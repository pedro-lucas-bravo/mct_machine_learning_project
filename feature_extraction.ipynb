{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of Direction of Arrival (DOA) for First Order Ambisonic Audio Files using Artificial Neural Networks\n",
    "\n",
    "**Pedro Pablo Lucas Bravo**\n",
    "\n",
    "**pedropl@uio.no**\n",
    "\n",
    "# Feature Extraction\n",
    "\n",
    "**Before running**: If you DONT want to save the features in a file set the next vatiable to FALSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa\n",
    "import os\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#Taken maths from: https://math.libretexts.org/Bookshelves/Calculus/Book%3A_Calculus_(OpenStax)/12%3A_Vectors_in_Space/12.7%3A_Cylindrical_and_Spherical_Coordinates#:~:text=To%20convert%20a%20point%20from,and%20z%3D%CF%81cos%CF%86.&text=To%20convert%20a%20point%20from,and%20z%3D%CF%81cos%CF%86.\n",
    "def SphericalToCartesian(ele, azi, dist):\n",
    "    phi = np.deg2rad(90-ele)\n",
    "    theta = np.deg2rad(azi)\n",
    "    \n",
    "    x = dist * np.sin(phi) * np.cos(theta)\n",
    "    #x=ρsinφcosθ \n",
    "    y = dist * np.sin(phi) * np.sin(theta)\n",
    "    #y=ρsinφsinθ \n",
    "    z = dist * np.cos(phi)\n",
    "    #z=ρcosφ\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "\n",
    "#Taken from ML workshop: defining function to interpolate 1-D dimensional arrays\n",
    "def lin_interp_1d(data, out_size):\n",
    "    \n",
    "    in_size = data.shape[0]\n",
    "    x_in = np.arange(0,in_size)\n",
    "    interpolator = scipy.interpolate.interp1d(x_in, data)\n",
    "    x_out = np.arange(0,in_size-1,((in_size-1)/out_size))\n",
    "    output = interpolator(x_out)\n",
    "    output = output[0:out_size]\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Taken from: https://stackoverflow.com/questions/21030391/how-to-normalize-a-numpy-array-to-a-unit-vector\n",
    "# It normalizes a vector such that the norm is 1\n",
    "def normalize(v):\n",
    "    norm=np.linalg.norm(v)\n",
    "    if norm==0:\n",
    "        norm=np.finfo(v.dtype).eps\n",
    "    return v/norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row feature extraction\n",
    "\n",
    "A *First Order Ambisonic (FOA)* audio file is composed of 4 channels that represent the components W, X, Y and Z. To create the feature the **cross power spectral density** is calculated for the pairs (W, X) , (W, Y), (W, Z) as a way to feed to the ML technique an example that considers the differences from these components relatively to the omnidirectional channel W in terms of distribution of power across the frequency spectrum along a time. From these spectrograms,  the *angle* was taken, since according to the literature and experiments, it performs well for DOA estimation. (More details in the report).\n",
    "\n",
    "Additionally, in order to reduce computational time and work with the same size for all files, the angle vector was interpolated to force a 256 size vector and then normalized to a number between -1 and 1. All channels are included as one only row, which is the final feature example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Signal: The 4-channel FOA audio signal\n",
    "#Location: a vector with the DOA as a vector in cartesian coordinates [x, y, z]\n",
    "def extract_features_target(signal, location, sr):\n",
    "    feature = []\n",
    "    for ch in range(1,4):    \n",
    "        cross = scipy.signal.csd(signal[0], signal[ch], fs = sr, nperseg=1024, noverlap=512)\n",
    "        cross = lin_interp_1d(np.angle(cross[1]), 256)\n",
    "        cross = librosa.util.normalize(cross)\n",
    "        feature = np.append(feature, cross)\n",
    "        \n",
    "    return feature, np.array(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading from Database and Extract Features\n",
    "\n",
    "The database contains a metadata file **metadata_dev.csv** and a set of audio files in the folder **foa_dev**. Each audio file has more than one sound event in the same recording. This code extracts all sound events and the features from their corresponding FOA audio file to a data-structure that will be saved later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training features...\n",
      "processing 'split1_ir0_ov1_1' 1/2\n",
      "processing 'split1_ir0_ov1_10' 2/2\n",
      "Done!\n",
      "Features Size:  (49, 768)\n",
      "Building testing features...\n",
      "processing 'split0_1' 1/2\n",
      "processing 'split0_10' 2/2\n",
      "Done!\n",
      "Features Size:  (55, 768)\n"
     ]
    }
   ],
   "source": [
    "sr = 22050 # Sample rate\n",
    "\n",
    "#It extracts for training and testing datasets\n",
    "#max_it is the number of files to consider, and max_num_examples the max number of sound events in the data set\n",
    "def build_examples(filenames_meta_dir, audiofiles_dir, max_it, max_num_examples):\n",
    "    filenames_meta = os.listdir(filenames_meta_dir) #Metadata file\n",
    "    num_features = 768 #Sixze of the feature vector considering 3x256 (3 correlations of 256 elements)\n",
    "    features = np.zeros((max_num_examples,num_features)) #The feature matrix\n",
    "    target = np.zeros((max_num_examples,3)) #3 target values [x,y,z] that represents the DOA as a normalized cartesian vector\n",
    "    meta_feat = pd.DataFrame(columns=['file_name', 'sound_event_recording', 'start_time', 'end_time', 'ele', 'azi', 'dist'])   #Metadata to add to the file in which features will be saved\n",
    "    example = 0\n",
    "\n",
    "    for i in range(max_it):  \n",
    "\n",
    "        #Metadata\n",
    "        metadata = pd.read_csv(filenames_meta_dir + '/' + filenames_meta[i])\n",
    "        filename = os.path.splitext(filenames_meta[i])[0]\n",
    "\n",
    "        print(\"processing '\" + filename + \"' \" + str(i + 1) + \"/\" + str(max_it))\n",
    "\n",
    "        #Audio track\n",
    "        signal, dummy = librosa.load(audiofiles_dir + '/' + filename + '.wav', sr, mono=False) \n",
    "        for s in range(len(metadata)):\n",
    "            start_time = int(metadata['start_time'][s] * sr)\n",
    "            end_time = int(metadata['end_time'][s] * sr)\n",
    "            subsignal = librosa.util.normalize(signal[:, start_time:end_time]) # Extract the sound event and normalize it \n",
    "            #Extract teh feature vector and convert polar coordinates to a normalized cartesian vector\n",
    "            features[example,:], target[example,:] = extract_features_target(subsignal, normalize(SphericalToCartesian(metadata['ele'][s],  metadata['azi'][s], metadata['dist'][s])), sr)\n",
    "            #Fill additional metadata\n",
    "            to_append = [filename, \n",
    "                              metadata['sound_event_recording'][s],\n",
    "                              metadata['start_time'][s],\n",
    "                              metadata['end_time'][s],\n",
    "                              metadata['ele'][s],\n",
    "                              metadata['azi'][s],\n",
    "                              metadata['dist'][s]\n",
    "                             ]\n",
    "            df_length = len(meta_feat)\n",
    "            meta_feat.loc[df_length] = to_append\n",
    "            example += 1\n",
    "\n",
    "    #Delete rows that are not being used if needed (it happens if max_it < 400 for features and 100 for test)          \n",
    "    features = np.delete(features, np.arange(example,features.shape[0], 1, dtype=int), axis=0)\n",
    "    target = np.delete(target, np.arange(example,target.shape[0], 1, dtype=int), axis=0)\n",
    "    print('Done!')\n",
    "    print('Features Size: ',features.shape)\n",
    "    return features, target, meta_feat\n",
    "    \n",
    "#Build the training feature matrix\n",
    "print('Building training features...')\n",
    "features_train, target_train, meta_train = build_examples('data/dcase_data/metadata_dev', 'data/dcase_data/foa_dev/', 2, 15798) #max 400\n",
    "    \n",
    "#Build the testing feature matrix\n",
    "print('Building testing features...')\n",
    "features_test, target_test, meta_test = build_examples('data/dcase_data/testing/metadata_eval', 'data/dcase_data/testing/foa_eval/', 2, 3974) #max 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Features to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving training features...\n",
      "Saving testing features...\n",
      "Done!\n",
      "TOTAL EXECUTION TIME:  12.637449026107788  sec\n"
     ]
    }
   ],
   "source": [
    "#merging everything into a single data structure\n",
    "def save_to_csv(features, target, meta_feat, file_name):\n",
    "    dataset = pd.DataFrame(features)\n",
    "\n",
    "    dataset['x'] = target[:,0]\n",
    "    dataset['y'] = target[:,1]\n",
    "    dataset['z'] = target[:,2]\n",
    "\n",
    "    dataset['file_name'] = meta_feat['file_name']\n",
    "    dataset['sound_event_recording'] = meta_feat['sound_event_recording']\n",
    "    dataset['start_time'] = meta_feat['start_time']\n",
    "    dataset['end_time'] = meta_feat['end_time']\n",
    "    dataset['ele'] = meta_feat['ele']\n",
    "    dataset['azi'] = meta_feat['azi']\n",
    "    dataset['dist'] = meta_feat['dist']\n",
    "\n",
    "    dataset.to_csv(file_name)\n",
    "\n",
    "if save:\n",
    "    # Saving training features\n",
    "    print('Saving training features...')\n",
    "    save_to_csv(features_train, target_train, meta_train, 'features_train.csv')\n",
    "\n",
    "    # Saving testing features\n",
    "    print('Saving testing features...')\n",
    "    save_to_csv(features_test, target_test, meta_test, 'features_test.csv')\n",
    "else:\n",
    "    print('Features were not saved!')\n",
    "print('Done!')\n",
    "print('TOTAL EXECUTION TIME: ', str(time.time() - start_time), ' sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
